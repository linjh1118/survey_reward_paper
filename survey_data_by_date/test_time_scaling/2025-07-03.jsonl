{"id": "2507.01951", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01951", "abs": "https://arxiv.org/abs/2507.01951", "authors": ["Zixiao Wang", "Yuxin Wang", "Xiaorui Wang", "Mengting Xing", "Jie Gao", "Jianjun Xu", "Guangcan Liu", "Chenhui Jin", "Zhuo Wang", "Shengzhuo Zhang", "Hongtao Xie"], "title": "Test-Time Scaling with Reflective Generative Model", "comment": null, "summary": "We introduce our first reflective generative model MetaStone-S1, which\nobtains OpenAI o3's performance via the self-supervised process reward model\n(SPRM). Through sharing the backbone network and using task-specific heads for\nnext token prediction and process scoring respectively, SPRM successfully\nintegrates the policy model and process reward model(PRM) into a unified\ninterface without extra process annotation, reducing over 99% PRM parameters\nfor efficient reasoning. Equipped with SPRM, MetaStone-S1 is naturally suitable\nfor test time scaling (TTS), and we provide three reasoning effort modes (low,\nmedium, and high), based on the controllable thinking length. Moreover, we\nempirically establish a scaling law that reveals the relationship between total\nthinking computation and TTS performance. Experiments demonstrate that our\nMetaStone-S1 achieves comparable performance to OpenAI-o3-mini's series with\nonly 32B parameter size. To support the research community, we have\nopen-sourced MetaStone-S1 at https://github.com/MetaStone-AI/MetaStone-S1.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["test-time", "test time", "scaling", "scaling law"], "score": 4}, "reward_model_rl": {"chapter_name": "Reward Model for RL", "matched_keywords": ["reward model"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["annotation"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01110", "categories": ["cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01110", "abs": "https://arxiv.org/abs/2507.01110", "authors": ["Felix Windisch", "Lukas Radl", "Thomas Köhler", "Michael Steiner", "Dieter Schmalstieg", "Markus Steinberger"], "title": "A LoD of Gaussians: Unified Training and Rendering for Ultra-Large Scale Reconstruction with External Memory", "comment": null, "summary": "Gaussian Splatting has emerged as a high-performance technique for novel view\nsynthesis, enabling real-time rendering and high-quality reconstruction of\nsmall scenes. However, scaling to larger environments has so far relied on\npartitioning the scene into chunks -- a strategy that introduces artifacts at\nchunk boundaries, complicates training across varying scales, and is poorly\nsuited to unstructured scenarios such as city-scale flyovers combined with\nstreet-level views. Moreover, rendering remains fundamentally limited by GPU\nmemory, as all visible chunks must reside in VRAM simultaneously. We introduce\nA LoD of Gaussians, a framework for training and rendering ultra-large-scale\nGaussian scenes on a single consumer-grade GPU -- without partitioning. Our\nmethod stores the full scene out-of-core (e.g., in CPU memory) and trains a\nLevel-of-Detail (LoD) representation directly, dynamically streaming only the\nrelevant Gaussians. A hybrid data structure combining Gaussian hierarchies with\nSequential Point Trees enables efficient, view-dependent LoD selection, while a\nlightweight caching and view scheduling system exploits temporal coherence to\nsupport real-time streaming and rendering. Together, these innovations enable\nseamless multi-scale reconstruction and interactive visualization of complex\nscenes -- from broad aerial views to fine-grained ground-level details.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scaling", "scale"], "score": 2}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["fine-grained"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01631", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01631", "abs": "https://arxiv.org/abs/2507.01631", "authors": ["Camille Billouard", "Dawa Derksen", "Alexandre Constantin", "Bruno Vallet"], "title": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "comment": "Accepted at ICCV 2025 Workshop 3D-VAST (From street to space: 3D\n  Vision Across Altitudes). Version before camera ready. Our code will be made\n  public after the conference", "summary": "Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D\nreconstruction from multiview satellite imagery. However, state-of-the-art NeRF\nmethods are typically constrained to small scenes due to the memory footprint\nduring training, which we study in this paper. Previous work on large-scale\nNeRFs palliate this by dividing the scene into NeRFs. This paper introduces\nSnake-NeRF, a framework that scales to large scenes. Our out-of-core method\neliminates the need to load all images and networks simultaneously, and\noperates on a single device. We achieve this by dividing the region of interest\ninto NeRFs that 3D tile without overlap. Importantly, we crop the images with\noverlap to ensure each NeRFs is trained with all the necessary pixels. We\nintroduce a novel $2\\times 2$ 3D tile progression strategy and segmented\nsampler, which together prevent 3D reconstruction errors along the tile edges.\nOur experiments conclude that large satellite images can effectively be\nprocessed with linear time complexity, on a single GPU, and without compromise\nin quality.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scaling", "scale"], "score": 2}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01347", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.01347", "abs": "https://arxiv.org/abs/2507.01347", "authors": ["Andrei Jelea", "Ahmed Nabil Belbachir", "Marius Leordeanu"], "title": "Learning from Random Subspace Exploration: Generalized Test-Time Augmentation with Self-supervised Distillation", "comment": null, "summary": "We introduce Generalized Test-Time Augmentation (GTTA), a highly effective\nmethod for improving the performance of a trained model, which unlike other\nexisting Test-Time Augmentation approaches from the literature is general\nenough to be used off-the-shelf for many vision and non-vision tasks, such as\nclassification, regression, image segmentation and object detection. By\napplying a new general data transformation, that randomly perturbs multiple\ntimes the PCA subspace projection of a test input, GTTA forms robust ensembles\nat test time in which, due to sound statistical properties, the structural and\nsystematic noises in the initial input data is filtered out and final estimator\nerrors are reduced. Different from other existing methods, we also propose a\nfinal self-supervised learning stage in which the ensemble output, acting as an\nunsupervised teacher, is used to train the initial single student model, thus\nreducing significantly the test time computational cost, at no loss in\naccuracy. Our tests and comparisons to strong TTA approaches and SoTA models on\nvarious vision and non-vision well-known datasets and tasks, such as image\nclassification and segmentation, speech recognition and house price prediction,\nvalidate the generality of the proposed GTTA. Furthermore, we also prove its\neffectiveness on the more specific real-world task of salmon segmentation and\ndetection in low-visibility underwater videos, for which we introduce\nDeepSalmon, the largest dataset of its kind in the literature.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["test-time", "test time"], "score": 2}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["dataset", "accuracy"], "score": 2}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01631", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01631", "abs": "https://arxiv.org/abs/2507.01631", "authors": ["Camille Billouard", "Dawa Derksen", "Alexandre Constantin", "Bruno Vallet"], "title": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "comment": "Accepted at ICCV 2025 Workshop 3D-VAST (From street to space: 3D\n  Vision Across Altitudes). Version before camera ready. Our code will be made\n  public after the conference", "summary": "Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D\nreconstruction from multiview satellite imagery. However, state-of-the-art NeRF\nmethods are typically constrained to small scenes due to the memory footprint\nduring training, which we study in this paper. Previous work on large-scale\nNeRFs palliate this by dividing the scene into NeRFs. This paper introduces\nSnake-NeRF, a framework that scales to large scenes. Our out-of-core method\neliminates the need to load all images and networks simultaneously, and\noperates on a single device. We achieve this by dividing the region of interest\ninto NeRFs that 3D tile without overlap. Importantly, we crop the images with\noverlap to ensure each NeRFs is trained with all the necessary pixels. We\nintroduce a novel $2\\times 2$ 3D tile progression strategy and segmented\nsampler, which together prevent 3D reconstruction errors along the tile edges.\nOur experiments conclude that large satellite images can effectively be\nprocessed with linear time complexity, on a single GPU, and without compromise\nin quality.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scaling", "scale"], "score": 2}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01829", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01829", "abs": "https://arxiv.org/abs/2507.01829", "authors": ["Tristan Torchet", "Christian Metzner", "Laura Kriener", "Melika Payvand"], "title": "mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling", "comment": null, "summary": "Edge devices for temporal processing demand models that capture both short-\nand long- range dynamics under tight memory constraints. While Transformers\nexcel at sequence modeling, their quadratic memory scaling with sequence length\nmakes them impractical for such settings. Recurrent Neural Networks (RNNs)\noffer constant memory but train sequentially, and Temporal Convolutional\nNetworks (TCNs), though efficient, scale memory with kernel size. To address\nthis, we propose mGRADE (mininally Gated Recurrent Architecture with Delay\nEmbedding), a hybrid-memory system that integrates a temporal 1D-convolution\nwith learnable spacings followed by a minimal gated recurrent unit (minGRU).\nThis design allows the convolutional layer to realize a flexible delay\nembedding that captures rapid temporal variations, while the recurrent module\nefficiently maintains global context with minimal memory overhead. We validate\nour approach on two synthetic tasks, demonstrating that mGRADE effectively\nseparates and preserves multi-scale temporal features. Furthermore, on\nchallenging pixel-by-pixel image classification benchmarks, mGRADE consistently\noutperforms both pure convolutional and pure recurrent counterparts using\napproximately 20% less memory footprint, highlighting its suitability for\nmemory-constrained temporal processing at the edge. This highlights mGRADE's\npromise as an efficient solution for memory-constrained multi-scale temporal\nprocessing at the edge.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scaling", "scale"], "score": 2}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01110", "categories": ["cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01110", "abs": "https://arxiv.org/abs/2507.01110", "authors": ["Felix Windisch", "Lukas Radl", "Thomas Köhler", "Michael Steiner", "Dieter Schmalstieg", "Markus Steinberger"], "title": "A LoD of Gaussians: Unified Training and Rendering for Ultra-Large Scale Reconstruction with External Memory", "comment": null, "summary": "Gaussian Splatting has emerged as a high-performance technique for novel view\nsynthesis, enabling real-time rendering and high-quality reconstruction of\nsmall scenes. However, scaling to larger environments has so far relied on\npartitioning the scene into chunks -- a strategy that introduces artifacts at\nchunk boundaries, complicates training across varying scales, and is poorly\nsuited to unstructured scenarios such as city-scale flyovers combined with\nstreet-level views. Moreover, rendering remains fundamentally limited by GPU\nmemory, as all visible chunks must reside in VRAM simultaneously. We introduce\nA LoD of Gaussians, a framework for training and rendering ultra-large-scale\nGaussian scenes on a single consumer-grade GPU -- without partitioning. Our\nmethod stores the full scene out-of-core (e.g., in CPU memory) and trains a\nLevel-of-Detail (LoD) representation directly, dynamically streaming only the\nrelevant Gaussians. A hybrid data structure combining Gaussian hierarchies with\nSequential Point Trees enables efficient, view-dependent LoD selection, while a\nlightweight caching and view scheduling system exploits temporal coherence to\nsupport real-time streaming and rendering. Together, these innovations enable\nseamless multi-scale reconstruction and interactive visualization of complex\nscenes -- from broad aerial views to fine-grained ground-level details.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scaling", "scale"], "score": 2}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["fine-grained"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01631", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01631", "abs": "https://arxiv.org/abs/2507.01631", "authors": ["Camille Billouard", "Dawa Derksen", "Alexandre Constantin", "Bruno Vallet"], "title": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "comment": "Accepted at ICCV 2025 Workshop 3D-VAST (From street to space: 3D\n  Vision Across Altitudes). Version before camera ready. Our code will be made\n  public after the conference", "summary": "Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D\nreconstruction from multiview satellite imagery. However, state-of-the-art NeRF\nmethods are typically constrained to small scenes due to the memory footprint\nduring training, which we study in this paper. Previous work on large-scale\nNeRFs palliate this by dividing the scene into NeRFs. This paper introduces\nSnake-NeRF, a framework that scales to large scenes. Our out-of-core method\neliminates the need to load all images and networks simultaneously, and\noperates on a single device. We achieve this by dividing the region of interest\ninto NeRFs that 3D tile without overlap. Importantly, we crop the images with\noverlap to ensure each NeRFs is trained with all the necessary pixels. We\nintroduce a novel $2\\times 2$ 3D tile progression strategy and segmented\nsampler, which together prevent 3D reconstruction errors along the tile edges.\nOur experiments conclude that large satellite images can effectively be\nprocessed with linear time complexity, on a single GPU, and without compromise\nin quality.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scaling", "scale"], "score": 2}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01163", "categories": ["cs.CV", "q-bio.CB", "q-bio.QM", "I.4.7"], "pdf": "https://arxiv.org/pdf/2507.01163", "abs": "https://arxiv.org/abs/2507.01163", "authors": ["Alán F. Muñoz", "Tim Treis", "Alexandr A. Kalinin", "Shatavisha Dasgupta", "Fabian Theis", "Anne E. Carpenter", "Shantanu Singh"], "title": "cp_measure: API-first feature extraction for image-based profiling workflows", "comment": "10 pages, 4 figures, 4 supplementary figures. CODEML Workshop paper\n  accepted (non-archival), as a part of ICML2025 events", "summary": "Biological image analysis has traditionally focused on measuring specific\nvisual properties of interest for cells or other entities. A complementary\nparadigm gaining increasing traction is image-based profiling - quantifying\nmany distinct visual features to form comprehensive profiles which may reveal\nhidden patterns in cellular states, drug responses, and disease mechanisms.\nWhile current tools like CellProfiler can generate these feature sets, they\npose significant barriers to automated and reproducible analyses, hindering\nmachine learning workflows. Here we introduce cp_measure, a Python library that\nextracts CellProfiler's core measurement capabilities into a modular, API-first\ntool designed for programmatic feature extraction. We demonstrate that\ncp_measure features retain high fidelity with CellProfiler features while\nenabling seamless integration with the scientific Python ecosystem. Through\napplications to 3D astrocyte imaging and spatial transcriptomics, we showcase\nhow cp_measure enables reproducible, automated image-based profiling pipelines\nthat scale effectively for machine learning applications in computational\nbiology.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01026", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01026", "abs": "https://arxiv.org/abs/2507.01026", "authors": ["Md Shakil Ahamed Shohag", "Q. M. Jonathan Wu", "Farhad Pourpanah"], "title": "Few-Shot Inspired Generative Zero-Shot Learning", "comment": null, "summary": "Generative zero-shot learning (ZSL) methods typically synthesize visual\nfeatures for unseen classes using predefined semantic attributes, followed by\ntraining a fully supervised classification model. While effective, these\nmethods require substantial computational resources and extensive synthetic\ndata, thereby relaxing the original ZSL assumptions. In this paper, we propose\nFSIGenZ, a few-shot-inspired generative ZSL framework that reduces reliance on\nlarge-scale feature synthesis. Our key insight is that class-level attributes\nexhibit instance-level variability, i.e., some attributes may be absent or\npartially visible, yet conventional ZSL methods treat them as uniformly\npresent. To address this, we introduce Model-Specific Attribute Scoring (MSAS),\nwhich dynamically re-scores class attributes based on model-specific\noptimization to approximate instance-level variability without access to unseen\ndata. We further estimate group-level prototypes as clusters of instances based\non MSAS-adjusted attribute scores, which serve as representative synthetic\nfeatures for each unseen class. To mitigate the resulting data imbalance, we\nintroduce a Dual-Purpose Semantic Regularization (DPSR) strategy while training\na semantic-aware contrastive classifier (SCC) using these prototypes.\nExperiments on SUN, AwA2, and CUB benchmarks demonstrate that FSIGenZ achieves\ncompetitive performance using far fewer synthetic features.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01255", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.01255", "abs": "https://arxiv.org/abs/2507.01255", "authors": ["Xiao Liu", "Jiawei Zhang"], "title": "AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation", "comment": "Working in Progress", "summary": "The rapid advancement of AI-generated video models has created a pressing\nneed for robust and interpretable evaluation frameworks. Existing metrics are\nlimited to producing numerical scores without explanatory comments, resulting\nin low interpretability and human evaluation alignment. To address those\nchallenges, we introduce AIGVE-MACS, a unified model for AI-Generated Video\nEvaluation(AIGVE), which can provide not only numerical scores but also\nmulti-aspect language comment feedback in evaluating these generated videos.\nCentral to our approach is AIGVE-BENCH 2, a large-scale benchmark comprising\n2,500 AI-generated videos and 22,500 human-annotated detailed comments and\nnumerical scores across nine critical evaluation aspects. Leveraging\nAIGVE-BENCH 2, AIGVE-MACS incorporates recent Vision-Language Models with a\nnovel token-wise weighted loss and a dynamic frame sampling strategy to better\nalign with human evaluators. Comprehensive experiments across supervised and\nzero-shot benchmarks demonstrate that AIGVE-MACS achieves state-of-the-art\nperformance in both scoring correlation and comment quality, significantly\noutperforming prior baselines including GPT-4o and VideoScore. In addition, we\nfurther showcase a multi-agent refinement framework where feedback from\nAIGVE-MACS drives iterative improvements in video generation, leading to 53.5%\nquality enhancement. This work establishes a new paradigm for comprehensive,\nhuman-aligned evaluation of AI-generated videos. We release the AIGVE-BENCH 2\nand AIGVE-MACS at https://huggingface.co/xiaoliux/AIGVE-MACS.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_rl": {"chapter_name": "Reward Model for RL", "matched_keywords": ["alignment"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["benchmark", "evaluation", "correlation"], "score": 3}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01140", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2507.01140", "abs": "https://arxiv.org/abs/2507.01140", "authors": ["Eric Zimmermann", "Stefan Bruckner"], "title": "Multi-Focus Probes for Context-Preserving Network Exploration and Interaction in Immersive Analytics", "comment": "5 pages, 3 figures, IEEE Vis 2025", "summary": "Immersive visualization of network data enables users to physically navigate\nand interact with complex structures, but managing transitions between detailed\nlocal (egocentric) views and global (exocentric) overviews remains a major\nchallenge. We present a multifocus probe technique for immersive environments\nthat allows users to instantiate multiple egocentric subgraph views while\nmaintaining persistent links to the global network context. Each probe acts as\na portable local focus, enabling fine-grained inspection and editing of distant\nor occluded regions. Visual and haptic guidance mechanisms ensure context\npreservation during multi-scale interaction. We demonstrate and discuss the\nusability of our technique for the editing of network data.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["fine-grained"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01081", "categories": ["cs.HC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01081", "abs": "https://arxiv.org/abs/2507.01081", "authors": ["Megan T. deBettencourt", "Sruthi Sakthivel", "Emily A. Holmes", "Mark Chevillet"], "title": "AI-guided digital intervention with physiological monitoring reduces intrusive memories after experimental trauma", "comment": null, "summary": "Trauma prevalence is vast globally. Evidence-based digital treatments can\nhelp, but most require human guidance. Human guides provide tailored\ninstructions and responsiveness to internal cognitive states, but limit\nscalability. Can generative AI and neurotechnology provide a scalable\nalternative? Here we test ANTIDOTE, combining AI guidance and pupillometry to\nautomatically deliver and monitor an evidence-based digital treatment,\nspecifically the Imagery Competing Task Intervention (ICTI), to reduce\nintrusive memories after psychological trauma. One hundred healthy volunteers\nwere exposed to videos of traumatic events and randomly assigned to an\nintervention or active control condition. As predicted, intervention\nparticipants reported significantly fewer intrusive memories over the following\nweek. Post-hoc assessment against clinical rubrics confirmed the AI guide\ndelivered the intervention successfully. Additionally, pupil size tracked\nintervention engagement and predicted symptom reduction, providing a candidate\nbiomarker of intervention effectiveness. These findings open a path toward\nrigorous AI-guided digital interventions that can scale to trauma prevalence.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01805", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.01805", "abs": "https://arxiv.org/abs/2507.01805", "authors": ["Alejandro Sosa Welford", "Leonardo Pepino"], "title": "A Dataset for Automatic Assessment of TTS Quality in Spanish", "comment": "5 pages, 2 figures. Accepted at Interspeech 2025", "summary": "This work addresses the development of a database for the automatic\nassessment of text-to-speech (TTS) systems in Spanish, aiming to improve the\naccuracy of naturalness prediction models. The dataset consists of 4,326 audio\nsamples from 52 different TTS systems and human voices and is, up to our\nknowledge, the first of its kind in Spanish. To label the audios, a subjective\ntest was designed based on the ITU-T Rec. P.807 standard and completed by 92\nparticipants. Furthermore, the utility of the collected dataset was validated\nby training automatic naturalness prediction systems. We explored two\napproaches: fine-tuning an existing model originally trained for English, and\ntraining small downstream networks on top of frozen self-supervised speech\nmodels. Our models achieve a mean absolute error of 0.8 on a five-point MOS\nscale. Further analysis demonstrates the quality and diversity of the developed\ndataset, and its potential to advance TTS research in Spanish.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["dataset", "accuracy"], "score": 2}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01247", "categories": ["eess.SY", "cs.SY", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2507.01247", "abs": "https://arxiv.org/abs/2507.01247", "authors": ["Roberto Sotero", "Jose Sanchez-Bornot"], "title": "Tunnelling Through Time Series: A Probabilistic Visibility Graph for Local and Global Pattern Discovery", "comment": null, "summary": "The growing availability of high-resolution, long-term time series data has\nhighlighted the need for methods capable of capturing both local and global\npatterns. To address this, we introduce the Probabilistic Visibility Graph\n(PVG), a novel approach inspired by the quantum tunnelling phenomenon. The PVG\nextends the classical Visibility Graph (VG) by introducing probabilistic\nconnections between time points that are obstructed in the VG due to\nintermediate values. We demonstrate the PVG's effectiveness in capturing\nlong-range dependencies through simulations of amplitude-modulated signals and\nanalysis of electrocorticography (ECoG) data under rest and anesthesia\nconditions. Key results show that the PVG presents distinct network properties\nbetween rest and anesthesia, with rest exhibiting stronger small-worldness and\nscale-free behavior, reflecting a hub-dominated, centralized connectivity\nstructure, compared to anesthesia. These findings highlight the PVG's potential\nfor analyzing complex signals with interacting temporal scales, offering new\ninsights into neural dynamics and other real-world phenomena.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01284", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01284", "abs": "https://arxiv.org/abs/2507.01284", "authors": ["Cristian Gariboldi", "Hayato Tokida", "Ken Kinjo", "Yuki Asada", "Alexander Carballo"], "title": "VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process", "comment": "2025 IEEE 28th International Conference on Intelligent Transportation\n  Systems (ITSC)", "summary": "Recent advancements in open-source Visual Language Models (VLMs) such as\nLLaVA, Qwen-VL, and Llama have catalyzed extensive research on their\nintegration with diverse systems. The internet-scale general knowledge\nencapsulated within these models presents significant opportunities for\nenhancing autonomous driving perception, prediction, and planning capabilities.\nIn this paper we propose VLAD, a vision-language autonomous driving model,\nwhich integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end\nsystem. We implement a specialized fine-tuning approach using custom\nquestion-answer datasets designed specifically to improve the spatial reasoning\ncapabilities of the model. The enhanced VLM generates high-level navigational\ncommands that VAD subsequently processes to guide vehicle operation.\nAdditionally, our system produces interpretable natural language explanations\nof driving decisions, thereby increasing transparency and trustworthiness of\nthe traditionally black-box end-to-end architecture. Comprehensive evaluation\non the real-world nuScenes dataset demonstrates that our integrated system\nreduces average collision rates by 31.82% compared to baseline methodologies,\nestablishing a new benchmark for VLM-augmented autonomous driving systems.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["benchmark", "evaluation", "dataset"], "score": 3}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01037", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.01037", "abs": "https://arxiv.org/abs/2507.01037", "authors": ["Wenbin Ouyang", "Sirui Li", "Yining Ma", "Cathy Wu"], "title": "Learning to Segment for Vehicle Routing Problems", "comment": null, "summary": "Iterative search heuristics are widely recognized as state-of-the-art for\nsolving Vehicle Routing Problems (VRPs). In this work, we identify and exploit\na critical observation: within these solvers, a large portion of the solution\nremains stable, i.e., unchanged across search iterations, causing redundant\ncomputations, especially for large-scale VRPs with long subtours. To address\nthis, we pioneer the formal study of the First-Segment-Then-Aggregate (FSTA)\ndecomposition technique to accelerate iterative solvers. Specifically, FSTA\npreserves stable solution segments during the search, aggregates nodes within\neach segment into fixed hypernodes, and focuses the search only on unstable\nportions. Yet, a key challenge lies in identifying which segments should be\naggregated by FSTA. To this end, we then introduce Learning-to-Segment (L2Seg),\na novel neural framework to intelligently differentiate potentially stable and\nunstable portions for FSTA decomposition. We present three L2Seg variants:\nnon-autoregressive (globally comprehensive but locally indiscriminate),\nautoregressive (locally refined but globally deficient), and their synergy,\nwith bespoke training and inference strategies. Empirical results on CVRP and\nVRPTW suggest that L2Seg accelerates state-of-the-art iterative solvers by up\nto 7x. Additionally, we provide in-depth analysis showing NAR and AR synergy\nachieves best performance by combining their complementary strengths. Notably,\nL2Seg is a flexible framework that is compatible with traditional,\nlearning-based, and hybrid solvers, while supporting a broad class of VRPs.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01424", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.01424", "abs": "https://arxiv.org/abs/2507.01424", "authors": ["Zhenyang Liu", "Yongchong Gu", "Sixiao Zheng", "Xiangyang Xue", "Yanwei Fu"], "title": "TriVLA: A Unified Triple-System-Based Unified Vision-Language-Action Model for General Robot Control", "comment": null, "summary": "Recent advancements in vision-language models (VLMs) for common-sense\nreasoning have led to the development of vision-language-action (VLA) models,\nenabling robots to perform generalized manipulation. Although existing\nautoregressive VLA methods design a specific architecture like dual-system to\nleverage large-scale pretrained knowledge, they tend to capture static\ninformation, often neglecting the dynamic aspects vital for embodied tasks. To\nthis end, we propose TriVLA, a unified Vision-Language-Action model with a\ntriple-system architecture for general robot control. The vision-language\nmodule (System 2) interprets the environment through vision and language\ninstructions. The dynamics perception module (System 3) inherently produces\nvisual representations that encompass both current static information and\npredicted future dynamics, thereby providing valuable guidance for policy\nlearning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trained\nvideo foundation model on robot datasets along with internet human manipulation\ndata. The subsequent policy learning module (System 1) generates fluid motor\nactions in real time. Experimental evaluation demonstrates that TriVLA operates\nat approximately 36 Hz and surpasses state-of-the-art imitation learning\nbaselines on standard simulation benchmarks as well as challenging real-world\nmanipulation tasks.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["evaluation"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01372", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01372", "abs": "https://arxiv.org/abs/2507.01372", "authors": ["Max Hamilton", "Jinlin Lai", "Wenlong Zhao", "Subhransu Maji", "Daniel Sheldon"], "title": "Active Measurement: Efficient Estimation at Scale", "comment": null, "summary": "AI has the potential to transform scientific discovery by analyzing vast\ndatasets with little human effort. However, current workflows often do not\nprovide the accuracy or statistical guarantees that are needed. We introduce\nactive measurement, a human-in-the-loop AI framework for scientific\nmeasurement. An AI model is used to predict measurements for individual units,\nwhich are then sampled for human labeling using importance sampling. With each\nnew set of human labels, the AI model is improved and an unbiased Monte Carlo\nestimate of the total measurement is refined. Active measurement can provide\nprecise estimates even with an imperfect AI model, and requires little human\neffort when the AI model is very accurate. We derive novel estimators,\nweighting schemes, and confidence intervals, and show that active measurement\nreduces estimation error compared to alternatives in several measurement tasks.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["accuracy"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01043", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01043", "abs": "https://arxiv.org/abs/2507.01043", "authors": ["Szymon Świderski", "Agnieszka Jastrzębska"], "title": "Data Classification with Dynamically Growing and Shrinking Neural Networks", "comment": "Paper submitted to Journal of Computational Science", "summary": "The issue of data-driven neural network model construction is one of the core\nproblems in the domain of Artificial Intelligence. A standard approach assumes\na fixed architecture with trainable weights. A conceptually more advanced\nassumption is that we not only train the weights, but also find out the optimal\nmodel architecture. We present a new method that realizes just that. This\narticle is an extended version of our conference paper titled \"Dynamic Growing\nand Shrinking of Neural Networks with Monte Carlo Tree Search [26]\". In the\npaper, we show in detail how to create a neural network with a procedure that\nallows dynamic shrinking and growing of the model while it is being trained.\nThe decision-making mechanism for the architectural design is governed by a\nMonte Carlo tree search procedure which simulates network behavior and allows\nto compare several candidate architecture changes to choose the best one. The\nproposed method was validated using both visual and time series datasets,\ndemonstrating its particular effectiveness in multivariate time series\nclassification. This is attributed to the architecture's ability to adapt\ndynamically, allowing independent modifications for each time series. The\napproach is supplemented by Python source code for reproducibility.\nExperimental evaluations in visual pattern and multivariate time series\nclassification tasks revealed highly promising performance, underscoring the\nmethod's robustness and adaptability.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["monte carlo tree search"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01727", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.01727", "abs": "https://arxiv.org/abs/2507.01727", "authors": ["Siyang Tang", "Wen-Hua Chen", "Cunjia Liu"], "title": "Auto-optimization of Energy Generation for Wave Energy Converters with Active Learning", "comment": null, "summary": "This paper presents an auto-optimization control framework for wave energy\nconverters (WECs) to maximize energy generation under unknown and changing\nocean conditions. The proposed control framework consists of two levels. The\nhigh-level controller operating at a longer time scale aims to maximize the\naverage energy generation over several wave periods. The generated Power\nTake-Off (PTO) profile as the reference for the low-level physical system to\nfollow. The new auto-optimization process leverages the parameterization of the\nnon-stationary operation condition in WECs, establishing the relationship\nbetween the average energy generation and the key design parameters of the PTO\nforce subject to the unknown wave parameters. The high-level controller is\ndesigned based on the concept of Dual Control for Exploration and Exploitation\n(DCEE) to quickly learn the unknown wave parameters by actively probing the\nocean condition, while generating the optimal PTO profile. During this process,\nthe uncertainty of the estimated wave condition is quantified and embedded in\nthe optimization cost function to enable active learning. Simulation results\nunder unknown regular and irregular waves demonstrate the effectiveness and\nrobustness of this novel auto-optimization WEC systems with active learning,\noutperforming model predictive control, extremum seeking and classic Bang-Bang\ncontrol approaches.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01045", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.01045", "abs": "https://arxiv.org/abs/2507.01045", "authors": ["Xiao Gu", "Wei Tang", "Jinpei Han", "Veer Sangha", "Fenglin Liu", "Shreyank N Gowda", "Antonio H. Ribeiro", "Patrick Schwab", "Kim Branson", "Lei Clifton", "Antonio Luiz P. Ribeiro", "Zhangdaihong Liu", "David A. Clifton"], "title": "Sensing Cardiac Health Across Scenarios and Devices: A Multi-Modal Foundation Model Pretrained on Heterogeneous Data from 1.7 Million Individuals", "comment": null, "summary": "Cardiac biosignals, such as electrocardiograms (ECG) and photoplethysmograms\n(PPG), are of paramount importance for the diagnosis, prevention, and\nmanagement of cardiovascular diseases, and have been extensively used in a\nvariety of clinical tasks. Conventional deep learning approaches for analyzing\nthese signals typically rely on homogeneous datasets and static bespoke models,\nlimiting their robustness and generalizability across diverse clinical settings\nand acquisition protocols. In this study, we present a cardiac sensing\nfoundation model (CSFM) that leverages advanced transformer architectures and a\ngenerative, masked pretraining strategy to learn unified representations from\nvast, heterogeneous health records. Our model is pretrained on an innovative\nmulti-modal integration of data from multiple large-scale datasets (including\nMIMIC-III-WDB, MIMIC-IV-ECG, and CODE), comprising cardiac signals and the\ncorresponding clinical or machine-generated text reports from approximately 1.7\nmillion individuals. We demonstrate that the embeddings derived from our CSFM\nnot only serve as effective feature extractors across diverse cardiac sensing\nscenarios, but also enable seamless transfer learning across varying input\nconfigurations and sensor modalities. Extensive evaluations across diagnostic\ntasks, demographic information recognition, vital sign measurement, clinical\noutcome prediction, and ECG question answering reveal that CSFM consistently\noutperforms traditional one-modal-one-task approaches. Notably, CSFM exhibits\nrobust performance across multiple ECG lead configurations from standard\n12-lead systems to single-lead setups, and in scenarios where only ECG, only\nPPG, or a combination thereof is available. These findings highlight the\npotential of CSFM as a versatile and scalable solution, for comprehensive\ncardiac monitoring.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["question answering"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01862", "categories": ["cs.HC", "cs.AI", "H.5.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2507.01862", "abs": "https://arxiv.org/abs/2507.01862", "authors": ["Sanjay Krishna Anbalagan", "Xinrui Nie", "Umesh Mohan", "Vijay Kumar Kanamarlapudi", "Anughna Kommalapati", "Xiaodan Zhao"], "title": "Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents", "comment": "8 pages, 1 figure, pre-print of poster accepted for HCI International\n  2025 (HCII 2025), CCIS vol 2529", "summary": "Domain specific chatbot applications often involve multi step interactions,\nsuch as refining search filters, selecting multiple items, or performing\ncomparisons. Traditional graphical user interfaces (GUIs) handle these\nworkflows by providing explicit \"Submit\" (commit data) and \"Reset\" (discard\ndata) actions, allowing back-end systems to track user intent unambiguously. In\ncontrast, conversational agents rely on subtle language cues, which can lead to\nconfusion and incomplete context management. This paper proposes modeling these\nGUI inspired metaphors acknowledgment (submit like) and context switching\n(reset-like) as explicit tasks within large language model (LLM) prompts. By\ncapturing user acknowledgment, reset actions, and chain of thought (CoT)\nreasoning as structured session data, we preserve clarity, reduce user\nconfusion, and align domain-specific chatbot interactions with back-end logic.\nWe demonstrate our approach in hotel booking and customer management scenarios,\nhighlighting improvements in multi-turn task coherence, user satisfaction, and\nefficiency.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["chain of thought"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01705", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.01705", "abs": "https://arxiv.org/abs/2507.01705", "authors": ["Marc-Philip Ecker", "Bernhard Bischof", "Minh Nhat Vu", "Christoph Fröhlich", "Tobias Glück", "Wolfgang Kemmetmüller"], "title": "Efficient Collision Detection for Long and Slender Robotic Links in Euclidean Distance Fields: Application to a Forestry Crane", "comment": "Accepted at IROS 2025", "summary": "Collision-free motion planning in complex outdoor environments relies heavily\non perceiving the surroundings through exteroceptive sensors. A widely used\napproach represents the environment as a voxelized Euclidean distance field,\nwhere robots are typically approximated by spheres. However, for large-scale\nmanipulators such as forestry cranes, which feature long and slender links,\nthis conventional spherical approximation becomes inefficient and inaccurate.\nThis work presents a novel collision detection algorithm specifically designed\nto exploit the elongated structure of such manipulators, significantly\nenhancing the computational efficiency of motion planning algorithms. Unlike\ntraditional sphere decomposition methods, our approach not only improves\ncomputational efficiency but also naturally eliminates the need to fine-tune\nthe approximation accuracy as an additional parameter. We validate the\nalgorithm's effectiveness using real-world LiDAR data from a forestry crane\napplication, as well as simulated environment data.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["accuracy"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01422", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01422", "abs": "https://arxiv.org/abs/2507.01422", "authors": ["Wenjie Liu", "Bingshu Wang", "Ze Wang", "C. L. Philip Chen"], "title": "DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal", "comment": null, "summary": "Document shadow removal is a crucial task in the field of document image\nenhancement. However, existing methods tend to remove shadows with constant\ncolor background and ignore color shadows. In this paper, we first design a\ndiffusion model in latent space for document image shadow removal, called\nDocShaDiffusion. It translates shadow images from pixel space to latent space,\nenabling the model to more easily capture essential features. To address the\nissue of color shadows, we design a shadow soft-mask generation module (SSGM).\nIt is able to produce accurate shadow mask and add noise into shadow regions\nspecially. Guided by the shadow mask, a shadow mask-aware guided diffusion\nmodule (SMGDM) is proposed to remove shadows from document images by\nsupervising the diffusion and denoising process. We also propose a\nshadow-robust perceptual feature loss to preserve details and structures in\ndocument images. Moreover, we develop a large-scale synthetic document color\nshadow removal dataset (SDCSRD). It simulates the distribution of realistic\ncolor shadows and provides powerful supports for the training of models.\nExperiments on three public datasets validate the proposed method's superiority\nover state-of-the-art. Our code and dataset will be publicly available.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["dataset"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01075", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.01075", "abs": "https://arxiv.org/abs/2507.01075", "authors": ["Gabriele Padovani", "Valentine Anantharaj", "Sandro Fiore"], "title": "Provenance Tracking in Large-Scale Machine Learning Systems", "comment": null, "summary": "As the demand for large scale AI models continues to grow, the optimization\nof their training to balance computational efficiency, execution time, accuracy\nand energy consumption represents a critical multidimensional challenge.\nAchieving this balance requires not only innovative algorithmic techniques and\nhardware architectures but also comprehensive tools for monitoring, analyzing,\nand understanding the underlying processes involved in model training and\ndeployment. Provenance data information about the origins, context, and\ntransformations of data and processes has become a key component in this\npursuit. By leveraging provenance, researchers and engineers can gain insights\ninto resource usage patterns, identify inefficiencies, and ensure\nreproducibility and accountability in AI development workflows. For this\nreason, the question of how distributed resources can be optimally utilized to\nscale large AI models in an energy efficient manner is a fundamental one. To\nsupport this effort, we introduce the yProv4ML library, a tool designed to\ncollect provenance data in JSON format, compliant with the W3C PROV and ProvML\nstandards. yProv4ML focuses on flexibility and extensibility, and enables users\nto integrate additional data collection tools via plugins. The library is fully\nintegrated with the yProv framework, allowing for higher level pairing in tasks\nrun also through workflow management systems.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["accuracy"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01037", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.01037", "abs": "https://arxiv.org/abs/2507.01037", "authors": ["Wenbin Ouyang", "Sirui Li", "Yining Ma", "Cathy Wu"], "title": "Learning to Segment for Vehicle Routing Problems", "comment": null, "summary": "Iterative search heuristics are widely recognized as state-of-the-art for\nsolving Vehicle Routing Problems (VRPs). In this work, we identify and exploit\na critical observation: within these solvers, a large portion of the solution\nremains stable, i.e., unchanged across search iterations, causing redundant\ncomputations, especially for large-scale VRPs with long subtours. To address\nthis, we pioneer the formal study of the First-Segment-Then-Aggregate (FSTA)\ndecomposition technique to accelerate iterative solvers. Specifically, FSTA\npreserves stable solution segments during the search, aggregates nodes within\neach segment into fixed hypernodes, and focuses the search only on unstable\nportions. Yet, a key challenge lies in identifying which segments should be\naggregated by FSTA. To this end, we then introduce Learning-to-Segment (L2Seg),\na novel neural framework to intelligently differentiate potentially stable and\nunstable portions for FSTA decomposition. We present three L2Seg variants:\nnon-autoregressive (globally comprehensive but locally indiscriminate),\nautoregressive (locally refined but globally deficient), and their synergy,\nwith bespoke training and inference strategies. Empirical results on CVRP and\nVRPTW suggest that L2Seg accelerates state-of-the-art iterative solvers by up\nto 7x. Additionally, we provide in-depth analysis showing NAR and AR synergy\nachieves best performance by combining their complementary strengths. Notably,\nL2Seg is a flexible framework that is compatible with traditional,\nlearning-based, and hybrid solvers, while supporting a broad class of VRPs.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01080", "categories": ["cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2507.01080", "abs": "https://arxiv.org/abs/2507.01080", "authors": ["Edouard Lansiaux", "Ramy Azzouz", "Emmanuel Chazard", "Amélie Vromant", "Eric Wiel"], "title": "Development and Comparative Evaluation of Three Artificial Intelligence Models (NLP, LLM, JEPA) for Predicting Triage in Emergency Departments: A 7-Month Retrospective Proof-of-Concept", "comment": "15 pages, 6 figures", "summary": "Triage errors, including undertriage and overtriage, are persistent\nchallenges in emergency departments (EDs). With increasing patient influx and\nstaff shortages, the integration of artificial intelligence (AI) into triage\nprotocols has gained attention. This study compares the performance of three AI\nmodels [Natural Language Processing (NLP), Large Language Models (LLM), and\nJoint Embedding Predictive Architecture (JEPA)] in predicting triage outcomes\nagainst the FRENCH scale and clinical practice.We conducted a retrospective\nanalysis of a prospectively recruited cohort gathering adult patient triage\ndata over a 7-month period at the Roger Salengro Hospital ED (Lille, France).\nThree AI models were trained and validated : (1) TRIAGEMASTER (NLP), (2)\nURGENTIAPARSE (LLM), and (3) EMERGINET (JEPA). Data included demographic\ndetails, verbatim chief complaints, vital signs, and triage outcomes based on\nthe FRENCH scale and GEMSA coding. The primary outcome was the concordance of\nAI-predicted triage level with the FRENCH gold-standard. It was assessed thanks\nto various indicators : F1-Score, Weighted Kappa, Spearman, MAE, RMSE. The LLM\nmodel (URGENTIAPARSE) showed higher accuracy (composite score: 2.514) compared\nto JEPA (EMERGINET, 0.438) and NLP (TRIAGEMASTER, -3.511), outperforming nurse\ntriage (-4.343). Secondary analyses highlighted the effectiveness of\nURGENTIAPARSE in predicting hospitalization needs (GEMSA) and its robustness\nwith structured data versus raw transcripts (either for GEMSA prediction or for\nFRENCH prediction). LLM architecture, through abstraction of patient\nrepresentations, offers the most accurate triage predictions among tested\nmodels. Integrating AI into ED workflows could enhance patient safety and\noperational efficiency, though integration into clinical workflows requires\naddressing model limitations and ensuring ethical transparency.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["evaluation", "safety", "kappa", "accuracy"], "score": 4}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01494", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01494", "abs": "https://arxiv.org/abs/2507.01494", "authors": ["Muhammad Hassam Ejaz", "Muhammad Bilal", "Usman Habib"], "title": "Crop Pest Classification Using Deep Learning Techniques: A Review", "comment": null, "summary": "Insect pests continue to bring a serious threat to crop yields around the\nworld, and traditional methods for monitoring them are often slow, manual, and\ndifficult to scale. In recent years, deep learning has emerged as a powerful\nsolution, with techniques like convolutional neural networks (CNNs), vision\ntransformers (ViTs), and hybrid models gaining popularity for automating pest\ndetection. This review looks at 37 carefully selected studies published between\n2018 and 2025, all focused on AI-based pest classification. The selected\nresearch is organized by crop type, pest species, model architecture, dataset\nusage, and key technical challenges. The early studies relied heavily on CNNs\nbut latest work is shifting toward hybrid and transformer-based models that\ndeliver higher accuracy and better contextual understanding. Still, challenges\nlike imbalanced datasets, difficulty in detecting small pests, limited\ngeneralizability, and deployment on edge devices remain significant hurdles.\nOverall, this review offers a structured overview of the field, highlights\nuseful datasets, and outlines the key challenges and future directions for\nAI-based pest monitoring systems.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["dataset", "accuracy"], "score": 2}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01129", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.01129", "abs": "https://arxiv.org/abs/2507.01129", "authors": ["Arun Ganesh", "Brendan McMahan", "Abhradeep Thakurta"], "title": "On Design Principles for Private Adaptive Optimizers", "comment": "PPML 2025", "summary": "The spherical noise added to gradients in differentially private (DP)\ntraining undermines the performance of adaptive optimizers like AdaGrad and\nAdam, and hence many recent works have proposed algorithms to address this\nchallenge. However, the empirical results in these works focus on simple tasks\nand models and the conclusions may not generalize to model training in\npractice. In this paper we survey several of these variants, and develop better\ntheoretical intuition for them as well as perform empirical studies comparing\nthem. We find that a common intuition of aiming for unbiased estimates of\nsecond moments of gradients in adaptive optimizers is misguided, and instead\nthat a simple technique called scale-then-privatize (which does not achieve\nunbiased second moments) has more desirable theoretical behaviors and\noutperforms all other variants we study on a small-scale language model\ntraining task. We additionally argue that scale-then-privatize causes the noise\naddition to better match the application of correlated noise mechanisms which\nare more desirable to use in practice.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01201", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.01201", "abs": "https://arxiv.org/abs/2507.01201", "authors": ["Hyoseo", "Yoon", "Yisong Yue", "Been Kim"], "title": "Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models", "comment": null, "summary": "Independently trained vision and language models inhabit disjoint\nrepresentational spaces, shaped by their respective modalities, objectives, and\narchitectures. Yet an emerging hypothesis - the Platonic Representation\nHypothesis - suggests that such models may nonetheless converge toward a shared\nstatistical model of reality. This compatibility, if it exists, raises a\nfundamental question: can we move beyond post-hoc statistical detection of\nalignment and explicitly optimize for it between such disjoint representations?\nWe cast this Platonic alignment problem as a multi-objective optimization task\n- preserve each modality's native structure while aligning for mutual\ncoherence. We introduce the Joint Autoencoder Modulator (JAM) framework that\njointly trains modality-specific autoencoders on the latent representations of\npre-trained single modality models, encouraging alignment through both\nreconstruction and cross-modal objectives. By analogy, this framework serves as\na method to escape Plato's Cave, enabling the emergence of shared structure\nfrom disjoint inputs. We evaluate this framework across three critical design\naxes: (i) the alignment objective - comparing contrastive loss (Con), its\nhard-negative variant (NegCon), and our Spread loss, (ii) the layer depth at\nwhich alignment is most effective, and (iii) the impact of foundation model\nscale on representational convergence. Our findings show that our lightweight\nPareto-efficient framework reliably induces alignment, even across frozen,\nindependently trained representations, offering both theoretical insight and\npractical pathways for transforming generalist unimodal foundations into\nspecialist multimodal models.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_rl": {"chapter_name": "Reward Model for RL", "matched_keywords": ["alignment"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01573", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.01573", "abs": "https://arxiv.org/abs/2507.01573", "authors": ["Hao Wang", "Keyan Hu", "Xin Guo", "Haifeng Li", "Chao Tao"], "title": "A Gift from the Integration of Discriminative and Diffusion-based Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation", "comment": "20 pages, 14 figures", "summary": "Remote sensing semantic segmentation must address both what the ground\nobjects are within an image and where they are located. Consequently,\nsegmentation models must ensure not only the semantic correctness of\nlarge-scale patches (low-frequency information) but also the precise\nlocalization of boundaries between patches (high-frequency information).\nHowever, most existing approaches rely heavily on discriminative learning,\nwhich excels at capturing low-frequency features, while overlooking its\ninherent limitations in learning high-frequency features for semantic\nsegmentation. Recent studies have revealed that diffusion generative models\nexcel at generating high-frequency details. Our theoretical analysis confirms\nthat the diffusion denoising process significantly enhances the model's ability\nto learn high-frequency features; however, we also observe that these models\nexhibit insufficient semantic inference for low-frequency features when guided\nsolely by the original image. Therefore, we integrate the strengths of both\ndiscriminative and generative learning, proposing the Integration of\nDiscriminative and diffusion-based Generative learning for Boundary Refinement\n(IDGBR) framework. The framework first generates a coarse segmentation map\nusing a discriminative backbone model. This map and the original image are fed\ninto a conditioning guidance network to jointly learn a guidance representation\nsubsequently leveraged by an iterative denoising diffusion process refining the\ncoarse segmentation. Extensive experiments across five remote sensing semantic\nsegmentation datasets (binary and multi-class segmentation) confirm our\nframework's capability of consistent boundary refinement for coarse results\nfrom diverse discriminative architectures. The source code will be available at\nhttps://github.com/KeyanHu-git/IDGBR.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01241", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01241", "abs": "https://arxiv.org/abs/2507.01241", "authors": ["Di Zhang", "Yihang Zhang"], "title": "Beyond First-Order: Training LLMs with Stochastic Conjugate Subgradients and AdamW", "comment": null, "summary": "Stochastic gradient-based descent (SGD), have long been central to training\nlarge language models (LLMs). However, their effectiveness is increasingly\nbeing questioned, particularly in large-scale applications where empirical\nevidence suggests potential performance limitations. In response, this paper\nproposes a stochastic conjugate subgradient method together with adaptive\nsampling tailored specifically for training LLMs. The method not only achieves\nfaster convergence per iteration but also demonstrates improved scalability\ncompared to traditional SGD techniques. It leverages sample complexity analysis\nto adaptively choose the sample size, employs a stochastic conjugate\nsubgradient approach to determine search directions and utilizing an AdamW-like\nalgorithm to adaptively adjust step sizes. This approach preserves the key\nadvantages of first-order methods while effectively addressing the nonconvexity\nand non-smoothness inherent in LLMs training. Additionally, we provide a\ndetailed analysis of the advantage of the algorithm. Experimental results show\nthat the proposed method not only maintains, but in many cases surpasses, the\nscalability of traditional SGD techniques, significantly enhancing both the\nspeed and accuracy of the optimization process.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["accuracy"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01603", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.01603", "abs": "https://arxiv.org/abs/2507.01603", "authors": ["Yue-Jiang Dong", "Wang Zhao", "Jiale Xu", "Ying Shan", "Song-Hai Zhang"], "title": "DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation", "comment": "Accepted by ICCV 2025", "summary": "Diffusion-based video depth estimation methods have achieved remarkable\nsuccess with strong generalization ability. However, predicting depth for long\nvideos remains challenging. Existing methods typically split videos into\noverlapping sliding windows, leading to accumulated scale discrepancies across\ndifferent windows, particularly as the number of windows increases.\nAdditionally, these methods rely solely on 2D diffusion priors, overlooking the\ninherent 3D geometric structure of video depths, which results in geometrically\ninconsistent predictions. In this paper, we propose DepthSync, a novel,\ntraining-free framework using diffusion guidance to achieve scale- and\ngeometry-consistent depth predictions for long videos. Specifically, we\nintroduce scale guidance to synchronize the depth scale across windows and\ngeometry guidance to enforce geometric alignment within windows based on the\ninherent 3D constraints in video depths. These two terms work synergistically,\nsteering the denoising process toward consistent depth predictions. Experiments\non various datasets validate the effectiveness of our method in producing depth\nestimates with improved scale and geometry consistency, particularly for long\nvideos.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_rl": {"chapter_name": "Reward Model for RL", "matched_keywords": ["alignment"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["consistency"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01327", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01327", "abs": "https://arxiv.org/abs/2507.01327", "authors": ["Xiaoyun Zhang", "Jingqing Ruan", "Xing Ma", "Yawen Zhu", "Jiansong Chen", "Ke Zeng", "Xunliang Cai"], "title": "Reasoner for Real-World Event Detection: Scaling Reinforcement Learning via Adaptive Perplexity-Aware Sampling Strategy", "comment": "15 pages, 6 figures, submitted to EMNLP", "summary": "Detecting abnormal events in real-world customer service dialogues is highly\nchallenging due to the complexity of business data and the dynamic nature of\ncustomer interactions. Moreover, models must demonstrate strong out-of-domain\n(OOD) generalization to enable rapid adaptation across different business\nscenarios and maximize commercial value. In this work, we propose a novel\nAdaptive Perplexity-Aware Reinforcement Learning (APARL) framework that\nleverages the advanced reasoning capabilities of large language models for\nabnormal event detection. APARL introduces a dual-loop dynamic curriculum\nlearning architecture, enabling the model to progressively focus on more\nchallenging samples as its proficiency increases. This design effectively\naddresses performance bottlenecks and significantly enhances OOD\ntransferability. Extensive evaluations on food delivery dialogue tasks show\nthat our model achieves significantly enhanced adaptability and robustness,\nattaining the highest F1 score with an average improvement of 17.19\\%, and an\naverage improvement of 9.59\\% in OOD transfer tests. This method provides a\nsuperior solution for industrial deployment of anomaly detection models,\ncontributing to improved operational efficiency and commercial benefits.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scaling"], "score": 1}, "reward_model_rl": {"chapter_name": "Reward Model for RL", "matched_keywords": ["reinforcement learning"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["dialogue"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01354", "categories": ["cs.LG", "physics.ao-ph", "86A10 (Primary) 86A22, 68U10 (Secondary)", "J.2; I.4.4"], "pdf": "https://arxiv.org/pdf/2507.01354", "abs": "https://arxiv.org/abs/2507.01354", "authors": ["Chugang Yi", "Minghan Yu", "Weikang Qian", "Yixin Wen", "Haizhao Yang"], "title": "Efficient Kilometer-Scale Precipitation Downscaling with Conditional Wavelet Diffusion", "comment": null, "summary": "Effective hydrological modeling and extreme weather analysis demand\nprecipitation data at a kilometer-scale resolution, which is significantly\nfiner than the 10 km scale offered by standard global products like IMERG. To\naddress this, we propose the Wavelet Diffusion Model (WDM), a generative\nframework that achieves 10x spatial super-resolution (downscaling to 1 km) and\ndelivers a 9x inference speedup over pixel-based diffusion models. WDM is a\nconditional diffusion model that learns the learns the complex structure of\nprecipitation from MRMS radar data directly in the wavelet domain. By focusing\non high-frequency wavelet coefficients, it generates exceptionally realistic\nand detailed 1-km precipitation fields. This wavelet-based approach produces\nvisually superior results with fewer artifacts than pixel-space models, and\ndelivers a significant gains in sampling efficiency. Our results demonstrate\nthat WDM provides a robust solution to the dual challenges of accuracy and\nspeed in geoscience super-resolution, paving the way for more reliable\nhydrological forecasts.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["accuracy"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01744", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.01744", "abs": "https://arxiv.org/abs/2507.01744", "authors": ["Benjamin Jin", "Grant Mair", "Joanna M. Wardlaw", "Maria del C. Valdés Hernández"], "title": "Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans", "comment": null, "summary": "Vision Transformers (ViTs) have gained significant popularity in the natural\nimage domain but have been less successful in 3D medical image segmentation.\nNevertheless, 3D ViTs are particularly interesting for large medical imaging\nvolumes due to their efficient self-supervised training within the masked\nautoencoder (MAE) framework, which enables the use of imaging data without the\nneed for expensive manual annotations. intracranial arterial calcification\n(IAC) is an imaging biomarker visible on routinely acquired CT scans linked to\nneurovascular diseases such as stroke and dementia, and automated IAC\nquantification could enable their large-scale risk assessment. We pre-train\nViTs with MAE and fine-tune them for IAC segmentation for the first time. To\ndevelop our models, we use highly heterogeneous data from a large clinical\ntrial, the third International Stroke Trial (IST-3). We evaluate key aspects of\nMAE pre-trained ViTs in IAC segmentation, and analyse the clinical\nimplications. We show: 1) our calibrated self-supervised ViT beats a strong\nsupervised nnU-Net baseline by 3.2 Dice points, 2) low patch sizes are crucial\nfor ViTs for IAC segmentation and interpolation upsampling with regular\nconvolutions is preferable to transposed convolutions for ViT-based models, and\n3) our ViTs increase robustness to higher slice thicknesses and improve risk\ngroup classification in a clinical scenario by 46%. Our code is available\nonline.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01791", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.01791", "abs": "https://arxiv.org/abs/2507.01791", "authors": ["Zihong Guo", "Chen Wan", "Yayin Zheng", "Hailing Kuang", "Xiaohai Lu"], "title": "Boosting Adversarial Transferability Against Defenses via Multi-Scale Transformation", "comment": null, "summary": "The transferability of adversarial examples poses a significant security\nchallenge for deep neural networks, which can be attacked without knowing\nanything about them. In this paper, we propose a new Segmented Gaussian Pyramid\n(SGP) attack method to enhance the transferability, particularly against\ndefense models. Unlike existing methods that generally focus on single-scale\nimages, our approach employs Gaussian filtering and three types of downsampling\nto construct a series of multi-scale examples. Then, the gradients of the loss\nfunction with respect to each scale are computed, and their average is used to\ndetermine the adversarial perturbations. The proposed SGP can be considered an\ninput transformation with high extensibility that is easily integrated into\nmost existing adversarial attacks. Extensive experiments demonstrate that in\ncontrast to the state-of-the-art methods, SGP significantly enhances attack\nsuccess rates against black-box defense models, with average attack success\nrates increasing by 2.3% to 32.6%, based only on transferability.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01740", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2507.01740", "abs": "https://arxiv.org/abs/2507.01740", "authors": ["Trung-Dung Hoang", "Alceu Bissoto", "Vihangkumar V. Naik", "Tim Flühmann", "Artemii Shlychkov", "José Garcia-Tirado", "Lisa M. Koch"], "title": "A Real-Time Digital Twin for Type 1 Diabetes using Simulation-Based Inference", "comment": null, "summary": "Accurately estimating parameters of physiological models is essential to\nachieving reliable digital twins. For Type 1 Diabetes, this is particularly\nchallenging due to the complexity of glucose-insulin interactions. Traditional\nmethods based on Markov Chain Monte Carlo struggle with high-dimensional\nparameter spaces and fit parameters from scratch at inference time, making them\nslow and computationally expensive. In this study, we propose a\nSimulation-Based Inference approach based on Neural Posterior Estimation to\nefficiently capture the complex relationships between meal intake, insulin, and\nglucose level, providing faster, amortized inference. Our experiments\ndemonstrate that SBI not only outperforms traditional methods in parameter\nestimation but also generalizes better to unseen conditions, offering real-time\nposterior inference with reliable uncertainty quantification.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["inference time"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01908", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.01908", "abs": "https://arxiv.org/abs/2507.01908", "authors": ["Qingdong He", "Xueqin Chen", "Chaoyi Wang", "Yanjie Pan", "Xiaobin Hu", "Zhenye Gan", "Yabiao Wang", "Chengjie Wang", "Xiangtai Li", "Jiangning Zhang"], "title": "Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning", "comment": null, "summary": "Instruction-based image editing (IIE) has advanced rapidly with the success\nof diffusion models. However, existing efforts primarily focus on simple and\nexplicit instructions to execute editing operations such as adding, deleting,\nmoving, or swapping objects. They struggle to handle more complex implicit\nhypothetical instructions that require deeper reasoning to infer plausible\nvisual changes and user intent. Additionally, current datasets provide limited\nsupport for training and evaluating reasoning-aware editing capabilities.\nArchitecturally, these methods also lack mechanisms for fine-grained detail\nextraction that support such reasoning. To address these limitations, we\npropose Reason50K, a large-scale dataset specifically curated for training and\nevaluating hypothetical instruction reasoning image editing, along with\nReasonBrain, a novel framework designed to reason over and execute implicit\nhypothetical instructions across diverse scenarios. Reason50K includes over 50K\nsamples spanning four key reasoning scenarios: Physical, Temporal, Causal, and\nStory reasoning. ReasonBrain leverages Multimodal Large Language Models (MLLMs)\nfor editing guidance generation and a diffusion model for image synthesis,\nincorporating a Fine-grained Reasoning Cue Extraction (FRCE) module to capture\ndetailed visual and textual semantics essential for supporting instruction\nreasoning. To mitigate the semantic loss, we further introduce a Cross-Modal\nEnhancer (CME) that enables rich interactions between the fine-grained cues and\nMLLM-derived features. Extensive experiments demonstrate that ReasonBrain\nconsistently outperforms state-of-the-art baselines on reasoning scenarios\nwhile exhibiting strong zero-shot generalization to conventional IIE tasks. Our\ndataset and code will be released publicly.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["dataset", "fine-grained"], "score": 2}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01831", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.01831", "abs": "https://arxiv.org/abs/2507.01831", "authors": ["Yucen Lily Li", "Daohan Lu", "Polina Kirichenko", "Shikai Qiu", "Tim G. J. Rudner", "C. Bayan Bruss", "Andrew Gordon Wilson"], "title": "Out-of-Distribution Detection Methods Answer the Wrong Questions", "comment": "Extended version of ICML 2025 paper", "summary": "To detect distribution shifts and improve model safety, many\nout-of-distribution (OOD) detection methods rely on the predictive uncertainty\nor features of supervised models trained on in-distribution data. In this\npaper, we critically re-examine this popular family of OOD detection\nprocedures, and we argue that these methods are fundamentally answering the\nwrong questions for OOD detection. There is no simple fix to this misalignment,\nsince a classifier trained only on in-distribution classes cannot be expected\nto identify OOD points; for instance, a cat-dog classifier may confidently\nmisclassify an airplane if it contains features that distinguish cats from\ndogs, despite generally appearing nothing alike. We find that uncertainty-based\nmethods incorrectly conflate high uncertainty with being OOD, while\nfeature-based methods incorrectly conflate far feature-space distance with\nbeing OOD. We show how these pathologies manifest as irreducible errors in OOD\ndetection and identify common settings where these methods are ineffective.\nAdditionally, interventions to improve OOD detection such as feature-logit\nhybrid methods, scaling of model and data size, epistemic uncertainty\nrepresentation, and outlier exposure also fail to address this fundamental\nmisalignment in objectives. We additionally consider unsupervised density\nestimation and generative models for OOD detection, which we show have their\nown fundamental limitations.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scaling"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["safety"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01201", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.01201", "abs": "https://arxiv.org/abs/2507.01201", "authors": ["Hyoseo", "Yoon", "Yisong Yue", "Been Kim"], "title": "Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models", "comment": null, "summary": "Independently trained vision and language models inhabit disjoint\nrepresentational spaces, shaped by their respective modalities, objectives, and\narchitectures. Yet an emerging hypothesis - the Platonic Representation\nHypothesis - suggests that such models may nonetheless converge toward a shared\nstatistical model of reality. This compatibility, if it exists, raises a\nfundamental question: can we move beyond post-hoc statistical detection of\nalignment and explicitly optimize for it between such disjoint representations?\nWe cast this Platonic alignment problem as a multi-objective optimization task\n- preserve each modality's native structure while aligning for mutual\ncoherence. We introduce the Joint Autoencoder Modulator (JAM) framework that\njointly trains modality-specific autoencoders on the latent representations of\npre-trained single modality models, encouraging alignment through both\nreconstruction and cross-modal objectives. By analogy, this framework serves as\na method to escape Plato's Cave, enabling the emergence of shared structure\nfrom disjoint inputs. We evaluate this framework across three critical design\naxes: (i) the alignment objective - comparing contrastive loss (Con), its\nhard-negative variant (NegCon), and our Spread loss, (ii) the layer depth at\nwhich alignment is most effective, and (iii) the impact of foundation model\nscale on representational convergence. Our findings show that our lightweight\nPareto-efficient framework reliably induces alignment, even across frozen,\nindependently trained representations, offering both theoretical insight and\npractical pathways for transforming generalist unimodal foundations into\nspecialist multimodal models.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_rl": {"chapter_name": "Reward Model for RL", "matched_keywords": ["alignment"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01284", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01284", "abs": "https://arxiv.org/abs/2507.01284", "authors": ["Cristian Gariboldi", "Hayato Tokida", "Ken Kinjo", "Yuki Asada", "Alexander Carballo"], "title": "VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process", "comment": "2025 IEEE 28th International Conference on Intelligent Transportation\n  Systems (ITSC)", "summary": "Recent advancements in open-source Visual Language Models (VLMs) such as\nLLaVA, Qwen-VL, and Llama have catalyzed extensive research on their\nintegration with diverse systems. The internet-scale general knowledge\nencapsulated within these models presents significant opportunities for\nenhancing autonomous driving perception, prediction, and planning capabilities.\nIn this paper we propose VLAD, a vision-language autonomous driving model,\nwhich integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end\nsystem. We implement a specialized fine-tuning approach using custom\nquestion-answer datasets designed specifically to improve the spatial reasoning\ncapabilities of the model. The enhanced VLM generates high-level navigational\ncommands that VAD subsequently processes to guide vehicle operation.\nAdditionally, our system produces interpretable natural language explanations\nof driving decisions, thereby increasing transparency and trustworthiness of\nthe traditionally black-box end-to-end architecture. Comprehensive evaluation\non the real-world nuScenes dataset demonstrates that our integrated system\nreduces average collision rates by 31.82% compared to baseline methodologies,\nestablishing a new benchmark for VLM-augmented autonomous driving systems.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["benchmark", "evaluation", "dataset"], "score": 3}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01284", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01284", "abs": "https://arxiv.org/abs/2507.01284", "authors": ["Cristian Gariboldi", "Hayato Tokida", "Ken Kinjo", "Yuki Asada", "Alexander Carballo"], "title": "VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process", "comment": "2025 IEEE 28th International Conference on Intelligent Transportation\n  Systems (ITSC)", "summary": "Recent advancements in open-source Visual Language Models (VLMs) such as\nLLaVA, Qwen-VL, and Llama have catalyzed extensive research on their\nintegration with diverse systems. The internet-scale general knowledge\nencapsulated within these models presents significant opportunities for\nenhancing autonomous driving perception, prediction, and planning capabilities.\nIn this paper we propose VLAD, a vision-language autonomous driving model,\nwhich integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end\nsystem. We implement a specialized fine-tuning approach using custom\nquestion-answer datasets designed specifically to improve the spatial reasoning\ncapabilities of the model. The enhanced VLM generates high-level navigational\ncommands that VAD subsequently processes to guide vehicle operation.\nAdditionally, our system produces interpretable natural language explanations\nof driving decisions, thereby increasing transparency and trustworthiness of\nthe traditionally black-box end-to-end architecture. Comprehensive evaluation\non the real-world nuScenes dataset demonstrates that our integrated system\nreduces average collision rates by 31.82% compared to baseline methodologies,\nestablishing a new benchmark for VLM-augmented autonomous driving systems.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["benchmark", "evaluation", "dataset"], "score": 3}}, "source_file": "2025-07-03.jsonl"}
{"id": "2507.01372", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01372", "abs": "https://arxiv.org/abs/2507.01372", "authors": ["Max Hamilton", "Jinlin Lai", "Wenlong Zhao", "Subhransu Maji", "Daniel Sheldon"], "title": "Active Measurement: Efficient Estimation at Scale", "comment": null, "summary": "AI has the potential to transform scientific discovery by analyzing vast\ndatasets with little human effort. However, current workflows often do not\nprovide the accuracy or statistical guarantees that are needed. We introduce\nactive measurement, a human-in-the-loop AI framework for scientific\nmeasurement. An AI model is used to predict measurements for individual units,\nwhich are then sampled for human labeling using importance sampling. With each\nnew set of human labels, the AI model is improved and an unbiased Monte Carlo\nestimate of the total measurement is refined. Active measurement can provide\nprecise estimates even with an imperfect AI model, and requires little human\neffort when the AI model is very accurate. We derive novel estimators,\nweighting schemes, and confidence intervals, and show that active measurement\nreduces estimation error compared to alternatives in several measurement tasks.", "survey_categories": {"test_time_scaling": {"chapter_name": "Test-Time Scaling", "matched_keywords": ["scale"], "score": 1}, "reward_model_benchmark": {"chapter_name": "Reward Model Benchmark", "matched_keywords": ["accuracy"], "score": 1}}, "source_file": "2025-07-03.jsonl"}
